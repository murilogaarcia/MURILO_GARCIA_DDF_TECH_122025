Este documento descreve **como qualquer pessoa consegue reproduzir todo o pipeline do case**, desde o banco local até os dashboards na Dadosfera.

---

#Arquitetura resumida

```text
PostgreSQL Local (Staging + Gold)
        ↓
ETL (Python / Pandas / SQL)
        ↓
Data Quality Checks
        ↓
Neon (Postgres Cloud)
        ↓
Dadosfera Pipelines
        ↓
Snowflake (Gold)
        ↓
Metabase (Dashboards)
Pré-requisitos
Você precisa de:
    -SQL Server Menagement Studio
    -Python 3.10+
    -PostgreSQL local
    -Conta Neon (Postgres Cloud)
    -Conta Dadosfera (Treinamentos)
    -Git
    -Jupyter Notebook

Fazer o Download da base de dados -> AdventureWorks2019
link: https://github.com/Microsoft/sql-server-samples/releases/download/adventureworks/AdventureWorks2019.bak
     -Importar o arquivo .bak ao SQL Server

Instalar dependências:

pip install pandas sqlalchemy psycopg2-binary jupyter
Executar o ETL local
Abra o notebook:

o jupyter notebook ETL_Case_DDF_TECH_dez2025.ipynb
Execute todas as células.

Este notebook:

Lê os dados do AdventureWorks

    -Inseri os dados brutos na camada raw
    -Trata e inseri os dados na camada Silver
    -Cria o schema gold
    -Cria as tabelas:
        gold.fact_sales
        gold.dim_product
        gold.dim_customer
        gold.dim_date
        gold.dim_special_offer

Rodar Data Quality
Execute:

    -python Data_Quality.py
    Este script:
    -Lê as tabelas Gold
    -Aplica regras de qualidade:
    -Not Null
    -Faixas numéricas
    -Valores permitidos

Gera:

    data_quality/relatorio_dq.csv
    data_quality/relatorio_dq.md

Ele valida colunas críticas como:

    -sales_order_id
    -order_date
    -product_id
    -customer_id
    -net_revenue
    -unit_price

    (Fonte: Data_Quality.py) 
    Data_Quality


Migrar para o Neon (Cloud)
Edite no arquivo Migrate_Neon.py a string de conexão do Neon, se necessário.

Execute:

bash
Copiar código
python Migrate_Neon.py
Este script:

Lê do PostgreSQL local (schema gold)

Cria o schema gold no Neon

Envia as tabelas:

    -fact_sales
    -dim_customer
    -dim_product
    -dim_date
    -dim_special_offer

(Fonte: Migrate_Neon.py) 
Migrate_Neon


Conectar Neon à Dadosfera
Na plataforma Dadosfera:

    Criar Data Source
    Tipo: PostgreSQL
    -Informar:
    -Host Neon
    -Database
    -User
    -Password
    -SSL = ON

Criar Pipeline
Criar pipeline:


    PostgreSQL (Neon) → Snowflake
    Selecionar as tabelas:

    gold.fact_sales

    gold.dim_product

    gold.dim_customer

    gold.dim_date

    gold.dim_special_offer

    Executar o pipeline até ficar SUCCESS.

Validar no Snowflake
Na Dadosfera (Metabase):

    Databases → Snowflake → PUBLIC
    Você verá as tabelas:

    TB_PA37IS_GOLD_FACT_SALES

    TB_PA37IS_GOLD_DIM_PRODUCT

    TB_PA37IS_GOLD_DIM_CUSTOMER

    TB_PA37IS_GOLD_DIM_DATE

    TB_PA37IS_GOLD_DIM_SPECIAL_OFFER

Criar Dashboards
No Metabase:

    -Criar nova pergunta
    -Usar Snowflake
    -Construir gráficos e métricas
    -Salvar no dashboard:
    -DashBoard_Case_DDFTECH_dez2025_MuriloGarcia

9O que garante reprodutibilidade
O case é 100% reproduzível porque:

    -ETL é versionado
    -Regras de qualidade são explícitas
    -Migração é automatizada
    -Infra cloud (Neon + Dadosfera) é declarada
    -Dados analíticos são rastreáveis da origem ao dashboard
    -Qualquer avaliador consegue executar o mesmo pipeline e obter os mesmos resultados.



